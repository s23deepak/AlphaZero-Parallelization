{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503e1ef9",
   "metadata": {},
   "source": [
    "# Convert AaduPulliEnv (Gymnasium) to PGX Environment\n",
    "This notebook demonstrates how to convert the custom Gymnasium environment `AaduPulliEnv` into a PGX-compatible environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30409b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: pgx in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: jax>=0.4.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pgx) (0.7.1)\n",
      "Requirement already satisfied: svgwrite in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pgx) (1.4.3)\n",
      "Requirement already satisfied: jaxlib<=0.7.1,>=0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (0.7.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in /home/codespace/.local/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (1.16.0)\n",
      "Requirement already satisfied: jax>=0.4.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pgx) (0.7.1)\n",
      "Requirement already satisfied: svgwrite in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pgx) (1.4.3)\n",
      "Requirement already satisfied: jaxlib<=0.7.1,>=0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (0.7.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/python/3.12.1/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in /home/codespace/.local/lib/python3.12/site-packages (from jax>=0.4.6->pgx) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install gymnasium pgx numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88eb0e",
   "metadata": {},
   "source": [
    "## Original AaduPulliEnv (Gymnasium) Implementation\n",
    "Below is the original custom environment code for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42b3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class AaduPulliEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        super(AaduPulliEnv, self).__init__()\n",
    "        self.NUM_GOATS = 15\n",
    "        self.NUM_TIGERS = 3\n",
    "        self.TIGER_WIN_THRESHOLD = 10\n",
    "        self.BOARD_POSITIONS = 23\n",
    "        self.MAX_TURNS = 200\n",
    "        self.adj = self._get_adjacency()\n",
    "        self.jump_adj = self._get_jump_adjacency()\n",
    "        self.placement_actions = self.BOARD_POSITIONS\n",
    "        self._move_action_map, self._move_action_lookup = self._create_move_maps()\n",
    "        self.move_actions_count = len(self._move_action_map)\n",
    "        total_actions = self.placement_actions + self.move_actions_count\n",
    "        self.action_space = spaces.Discrete(total_actions)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'board': spaces.Box(low=0, high=2, shape=(self.BOARD_POSITIONS,), dtype=np.int32),\n",
    "            'player_turn': spaces.Discrete(2),\n",
    "            'goats_to_place': spaces.Box(low=0, high=self.NUM_GOATS, shape=(1,), dtype=np.int32),\n",
    "            'goats_captured': spaces.Box(low=0, high=self.TIGER_WIN_THRESHOLD, shape=(1,), dtype=np.int32),\n",
    "        })\n",
    "        self.board_points = self._get_board_coordinates()\n",
    "        self.reset()\n",
    "    def _get_adjacency(self):\n",
    "        return {\n",
    "            1: [3, 4, 5, 6], 2: [3, 8], 3: [1, 4, 9, 2], 4: [1, 5, 10, 3], 5: [1, 6, 11, 4], 6: [1, 7, 12, 5], 7: [6, 13],\n",
    "            8: [2, 9, 14], 9: [3, 10, 15, 8], 10: [4, 11, 16, 9], 11: [5, 12, 17, 10], 12: [6, 13, 18, 11], 13: [7, 14, 12],\n",
    "            14: [8, 15], 15: [9, 16, 20, 14], 16: [10, 17, 21, 15], 17: [11, 18, 22, 16], 18: [12, 19, 23, 17], 19: [13, 18],\n",
    "            20: [15, 21], 21: [16, 20, 22], 22: [17, 21, 23], 23: [18, 22]\n",
    "        }\n",
    "    def _get_jump_adjacency(self):\n",
    "        return {\n",
    "            1: [9, 10, 11, 12], 2: [4, 14], 3: [5, 15], 4: [2, 6, 16], 5: [3, 7, 17], 6: [4, 18], 7: [5, 19],\n",
    "            8: [10], 9: [1, 11, 20], 10: [1, 8, 12, 21], 11: [1, 9, 13, 22], 12: [1, 10, 23], 13: [11],\n",
    "            14: [2, 16], 15: [3, 17], 16: [4, 14, 18], 17: [5, 15, 19], 18: [6, 16], 19: [7, 17],\n",
    "            20: [9, 22], 21: [10, 23], 22: [11, 20], 23: [12, 21]\n",
    "        }\n",
    "    def _create_move_maps(self):\n",
    "        action_map, action_lookup, index = {}, {}, 0\n",
    "        for start_pos in range(1, self.BOARD_POSITIONS + 1):\n",
    "            for end_pos in self.adj.get(start_pos, []):\n",
    "                move = (start_pos, end_pos); action_map[index] = move; action_lookup[move] = index; index += 1\n",
    "            for end_pos in self.jump_adj.get(start_pos, []):\n",
    "                move = (start_pos, end_pos)\n",
    "                if move not in action_lookup:\n",
    "                    action_map[index] = move; action_lookup[move] = index; index += 1\n",
    "        return action_map, action_lookup\n",
    "    def is_action_valid(self, action):\n",
    "        if not (0 <= action < self.action_space.n): return False, {'error': 'Action out of bounds.'}\n",
    "        if action < self.placement_actions:\n",
    "            to_idx = action\n",
    "            if self.player_turn != 0 or self.goats_placed_count >= self.NUM_GOATS: return False, {'error': 'Cannot place piece now.'}\n",
    "            if self.board[to_idx] != 0: return False, {'error': 'Destination square is not empty.'}\n",
    "            return True, {'type': 'place', 'to_idx': to_idx}\n",
    "        move_idx = action - self.placement_actions; from_pos, to_pos = self._move_action_map[move_idx]; from_idx, to_idx = from_pos - 1, to_pos - 1\n",
    "        if self.board[to_idx] != 0: return False, {'error': 'Destination square is not empty.'}\n",
    "        if self.player_turn == 0:\n",
    "            if self.goats_placed_count < self.NUM_GOATS: return False, {'error': 'Goat is still in placement phase.'}\n",
    "            if self.board[from_idx] != 1: return False, {'error': 'Player must move a goat.'}\n",
    "            if to_pos not in self.adj.get(from_pos, []): return False, {'error': 'Goat can only move to adjacent squares.'}\n",
    "            return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx}\n",
    "        else:\n",
    "            if self.board[from_idx] != 2: return False, {'error': 'Player must move a tiger.'}\n",
    "            if to_pos in self.adj.get(from_pos, []): return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx, 'is_jump': False}\n",
    "            if to_pos in self.jump_adj.get(from_pos, []):\n",
    "                from_neighbors = set(self.adj.get(from_pos, [])); to_neighbors = set(self.adj.get(to_pos, [])); mid_pos_set = from_neighbors.intersection(to_neighbors)\n",
    "                if mid_pos_set:\n",
    "                    mid_pos = mid_pos_set.pop()\n",
    "                    if self.board[mid_pos - 1] == 1: return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx, 'is_jump': True, 'mid_idx': mid_pos - 1}\n",
    "            return False, {'error': 'Invalid tiger move.'}\n",
    "    def _are_tigers_blocked(self):\n",
    "        for t_idx in np.where(self.board == 2)[0]:\n",
    "            t_pos = t_idx + 1\n",
    "            for dest_pos in self.adj.get(t_pos, []):\n",
    "                if self.board[dest_pos - 1] == 0: return False\n",
    "            for dest_pos in self.jump_adj.get(t_pos, []):\n",
    "                if self.board[dest_pos - 1] == 0:\n",
    "                    from_neighbors = set(self.adj.get(t_pos, [])); to_neighbors = set(self.adj.get(dest_pos, [])); mid_pos_set = from_neighbors.intersection(to_neighbors)\n",
    "                    if mid_pos_set and self.board[mid_pos_set.pop() - 1] == 1: return False\n",
    "        return True\n",
    "    def _get_current_observation(self):\n",
    "        return {\"board\":self.board.copy(),\"player_turn\":self.player_turn,\"goats_to_place\":np.array([self.NUM_GOATS-self.goats_placed_count],dtype=np.int32),\"goats_captured\":np.array([self.goats_captured_count],dtype=np.int32)}\n",
    "    def reset(self):\n",
    "        self.board=np.zeros(self.BOARD_POSITIONS,dtype=np.int32); self.board[0]=2; self.board[3]=2; self.board[4]=2;self.player_turn=0; self.goats_placed_count=0; self.goats_captured_count=0; self.turn_count=0\n",
    "        return self._get_current_observation()\n",
    "    def step(self, action):\n",
    "        is_valid, details = self.is_action_valid(action);reward, done, info = 0, False, details\n",
    "        if not is_valid: reward = -1\n",
    "        else:\n",
    "            if details['type']=='place': self.board[details['to_idx']]=1; self.goats_placed_count+=1\n",
    "            elif details['type']=='move':\n",
    "                p=self.board[details['from_idx']]; self.board[details['from_idx']]=0; self.board[details['to_idx']]=p\n",
    "                if p==2 and details.get('is_jump'): self.board[details['mid_idx']]=0; self.goats_captured_count+=1; reward=5\n",
    "            g_win=self._are_tigers_blocked(); t_win=self.goats_captured_count>=self.TIGER_WIN_THRESHOLD\n",
    "            if g_win: done=True; reward=100 if self.player_turn == 0 else -100; info['winner']=0\n",
    "            elif t_win: done=True; reward=100 if self.player_turn == 1 else -100; info['winner']=1\n",
    "            self.player_turn=1-self.player_turn; self.turn_count+=1\n",
    "        if not done and self.turn_count>=self.MAX_TURNS: done=True; info['winner']=-1\n",
    "        return self._get_current_observation(), reward, done, info\n",
    "    def _get_board_coordinates(self):\n",
    "        return {1:(12,20), 2:(1,16),3:(9.2,16),4:(10.7,16),5:(13.3,16),6:(14.8,16),7:(23,16), 8:(1,12),9:(6.5,12),10:(9.5,12),11:(14.5,12),12:(17.5,12),13:(23,12), 14:(1,8),15:(3.8,8),16:(8.3,8),17:(15.7,8),18:(20.3,8),19:(23,8), 20:(1,4),21:(7,4),22:(17,4),23:(23,4)}\n",
    "    def copy(self):\n",
    "        new_env = AaduPulliEnv(); new_env.board = self.board.copy(); new_env.player_turn = self.player_turn; new_env.goats_placed_count = self.goats_placed_count; new_env.goats_captured_count = self.goats_captured_count; new_env.turn_count = self.turn_count\n",
    "        return new_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011c036",
   "metadata": {},
   "source": [
    "## PGX Environment Overview\n",
    "PGX is a fast RL environment library for board games. To convert a Gymnasium environment to PGX, we need to implement the PGX API: `step`, `reset`, `legal_actions`, `current_player`, and `state_to_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41d4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgx\n",
    "import numpy as np\n",
    "class AaduPulliPGXEnv(pgx.Env):\n",
    "    def id(self):\n",
    "        return \"aadupulli\"\n",
    "    def version(self):\n",
    "        return \"v0\"\n",
    "    def num_players(self):\n",
    "        return 2\n",
    "    def _init(self):\n",
    "        self.NUM_GOATS = 15\n",
    "        self.NUM_TIGERS = 3\n",
    "        self.TIGER_WIN_THRESHOLD = 10\n",
    "        self.BOARD_POSITIONS = 23\n",
    "        self.MAX_TURNS = 200\n",
    "        self.adj = self._get_adjacency()\n",
    "        self.jump_adj = self._get_jump_adjacency()\n",
    "        self.placement_actions = self.BOARD_POSITIONS\n",
    "        self._move_action_map, self._move_action_lookup = self._create_move_maps()\n",
    "        self.move_actions_count = len(self._move_action_map)\n",
    "        self.total_actions = self.placement_actions + self.move_actions_count\n",
    "        self.reset()\n",
    "        return self._get_state()\n",
    "    def _observe(self, state, player):\n",
    "        return state['observation']\n",
    "    def _step(self, state, action):\n",
    "        self.board = state['observation']['board']\n",
    "        self.player_turn = state['observation']['player_turn']\n",
    "        self.goats_placed_count = self.NUM_GOATS - state['observation']['goats_to_place']\n",
    "        self.goats_captured_count = state['observation']['goats_captured']\n",
    "        self.turn_count = state.get('turn_count', 0)\n",
    "        next_state, reward, done, info = self._step_game(action)\n",
    "        return next_state, reward, done, info\n",
    "    def _step_game(self, action):\n",
    "        is_valid, details = self.is_action_valid(action)\n",
    "        reward, done, info = 0, False, details\n",
    "        if not is_valid:\n",
    "            reward = -1\n",
    "        else:\n",
    "            if details['type'] == 'place':\n",
    "                self.board[details['to_idx']] = 1; self.goats_placed_count += 1\n",
    "            elif details['type'] == 'move':\n",
    "                p = self.board[details['from_idx']]; self.board[details['from_idx']] = 0; self.board[details['to_idx']] = p\n",
    "                if p == 2 and details.get('is_jump'):\n",
    "                    self.board[details['mid_idx']] = 0; self.goats_captured_count += 1; reward = 5\n",
    "            g_win = self._are_tigers_blocked(); t_win = self.goats_captured_count >= self.TIGER_WIN_THRESHOLD\n",
    "            if g_win: done = True; reward = 100 if self.player_turn == 0 else -100; info['winner'] = 0\n",
    "            elif t_win: done = True; reward = 100 if self.player_turn == 1 else -100; info['winner'] = 1\n",
    "            self.player_turn = 1 - self.player_turn; self.turn_count += 1\n",
    "        if not done and self.turn_count >= self.MAX_TURNS: done = True; info['winner'] = -1\n",
    "        return self._get_state(), reward, done, info\n",
    "    def _get_adjacency(self):\n",
    "        # ...same as Gym env...\n",
    "        return {\n",
    "            1: [3, 4, 5, 6], 2: [3, 8], 3: [1, 4, 9, 2], 4: [1, 5, 10, 3], 5: [1, 6, 11, 4], 6: [1, 7, 12, 5], 7: [6, 13],\n",
    "            8: [2, 9, 14], 9: [3, 10, 15, 8], 10: [4, 11, 16, 9], 11: [5, 12, 17, 10], 12: [6, 13, 18, 11], 13: [7, 14, 12],\n",
    "            14: [8, 15], 15: [9, 16, 20, 14], 16: [10, 17, 21, 15], 17: [11, 18, 22, 16], 18: [12, 19, 23, 17], 19: [13, 18],\n",
    "            20: [15, 21], 21: [16, 20, 22], 22: [17, 21, 23], 23: [18, 22]\n",
    "        }\n",
    "    def _get_jump_adjacency(self):\n",
    "        # ...same as Gym env...\n",
    "        return {\n",
    "            1: [9, 10, 11, 12], 2: [4, 14], 3: [5, 15], 4: [2, 6, 16], 5: [3, 7, 17], 6: [4, 18], 7: [5, 19],\n",
    "            8: [10], 9: [1, 11, 20], 10: [1, 8, 12, 21], 11: [1, 9, 13, 22], 12: [1, 10, 23], 13: [11],\n",
    "            14: [2, 16], 15: [3, 17], 16: [4, 14, 18], 17: [5, 15, 19], 18: [6, 16], 19: [7, 17],\n",
    "            20: [9, 22], 21: [10, 23], 22: [11, 20], 23: [12, 21]\n",
    "        }\n",
    "    def _create_move_maps(self):\n",
    "        action_map, action_lookup, index = {}, {}, 0\n",
    "        for start_pos in range(1, self.BOARD_POSITIONS + 1):\n",
    "            for end_pos in self.adj.get(start_pos, []):\n",
    "                move = (start_pos, end_pos); action_map[index] = move; action_lookup[move] = index; index += 1\n",
    "            for end_pos in self.jump_adj.get(start_pos, []):\n",
    "                move = (start_pos, end_pos)\n",
    "                if move not in action_lookup:\n",
    "                    action_map[index] = move; action_lookup[move] = index; index += 1\n",
    "        return action_map, action_lookup\n",
    "    def reset(self):\n",
    "        self.board = np.zeros(self.BOARD_POSITIONS, dtype=np.int32)\n",
    "        self.board[0] = 2; self.board[3] = 2; self.board[4] = 2\n",
    "        self.player_turn = 0\n",
    "        self.goats_placed_count = 0\n",
    "        self.goats_captured_count = 0\n",
    "        self.turn_count = 0\n",
    "        return self._get_state()\n",
    "    def is_action_valid(self, action):\n",
    "        # ...same as Gym env...\n",
    "        if not (0 <= action < self.total_actions): return False, {'error': 'Action out of bounds.'}\n",
    "        if action < self.placement_actions:\n",
    "            to_idx = action\n",
    "            if self.player_turn != 0 or self.goats_placed_count >= self.NUM_GOATS: return False, {'error': 'Cannot place piece now.'}\n",
    "            if self.board[to_idx] != 0: return False, {'error': 'Destination square is not empty.'}\n",
    "            return True, {'type': 'place', 'to_idx': to_idx}\n",
    "        move_idx = action - self.placement_actions; from_pos, to_pos = self._move_action_map[move_idx]; from_idx, to_idx = from_pos - 1, to_pos - 1\n",
    "        if self.board[to_idx] != 0: return False, {'error': 'Destination square is not empty.'}\n",
    "        if self.player_turn == 0:\n",
    "            if self.goats_placed_count < self.NUM_GOATS: return False, {'error': 'Goat is still in placement phase.'}\n",
    "            if self.board[from_idx] != 1: return False, {'error': 'Player must move a goat.'}\n",
    "            if to_pos not in self.adj.get(from_pos, []): return False, {'error': 'Goat can only move to adjacent squares.'}\n",
    "            return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx}\n",
    "        else:\n",
    "            if self.board[from_idx] != 2: return False, {'error': 'Player must move a tiger.'}\n",
    "            if to_pos in self.adj.get(from_pos, []): return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx, 'is_jump': False}\n",
    "            if to_pos in self.jump_adj.get(from_pos, []):\n",
    "                from_neighbors = set(self.adj.get(from_pos, [])); to_neighbors = set(self.adj.get(to_pos, [])); mid_pos_set = from_neighbors.intersection(to_neighbors)\n",
    "                if mid_pos_set:\n",
    "                    mid_pos = mid_pos_set.pop()\n",
    "                    if self.board[mid_pos - 1] == 1: return True, {'type': 'move', 'from_idx': from_idx, 'to_idx': to_idx, 'is_jump': True, 'mid_idx': mid_pos - 1}\n",
    "            return False, {'error': 'Invalid tiger move.'}\n",
    "    def _are_tigers_blocked(self):\n",
    "        # ...same as Gym env...\n",
    "        for t_idx in np.where(self.board == 2)[0]:\n",
    "            t_pos = t_idx + 1\n",
    "            for dest_pos in self.adj.get(t_pos, []):\n",
    "                if self.board[dest_pos - 1] == 0: return False\n",
    "            for dest_pos in self.jump_adj.get(t_pos, []):\n",
    "                if self.board[dest_pos - 1] == 0:\n",
    "                    from_neighbors = set(self.adj.get(t_pos, [])); to_neighbors = set(self.adj.get(dest_pos, [])); mid_pos_set = from_neighbors.intersection(to_neighbors)\n",
    "                    if mid_pos_set and self.board[mid_pos_set.pop() - 1] == 1: return False\n",
    "        return True\n",
    "    def _get_state(self):\n",
    "        # PGX expects a dict with 'observation', 'current_player', 'legal_actions', etc.\n",
    "        obs = {\n",
    "            'board': self.board.copy(),\n",
    "            'player_turn': self.player_turn,\n",
    "            'goats_to_place': self.NUM_GOATS - self.goats_placed_count,\n",
    "            'goats_captured': self.goats_captured_count\n",
    "        }\n",
    "        return {\n",
    "            'observation': obs,\n",
    "            'current_player': self.player_turn,\n",
    "            'legal_actions': self.legal_actions(),\n",
    "        }\n",
    "    def legal_actions(self):\n",
    "        actions = []\n",
    "        for a in range(self.total_actions):\n",
    "            valid, _ = self.is_action_valid(a)\n",
    "            if valid:\n",
    "                actions.append(a)\n",
    "        return actions\n",
    "    def current_player(self):\n",
    "        return self.player_turn\n",
    "    def state_to_tensor(self):\n",
    "        # Example: flatten board and add player_turn, goats_to_place, goats_captured\n",
    "        return np.concatenate([self.board, [self.player_turn, self.NUM_GOATS - self.goats_placed_count, self.goats_captured_count]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd1c93",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "Instantiate and interact with the PGX environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372702ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: {'observation': {'board': array([2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int32), 'player_turn': 0, 'goats_to_place': 15, 'goats_captured': 0}, 'current_player': 0, 'legal_actions': [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}\n",
      "Legal actions: [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Next state: {'observation': {'board': array([2, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int32), 'player_turn': 1, 'goats_to_place': 14, 'goats_captured': 0}, 'current_player': 1, 'legal_actions': [23, 26, 43, 44, 49, 50]}\n",
      "Reward: 0 Done: False Info: {'type': 'place', 'to_idx': 1}\n"
     ]
    }
   ],
   "source": [
    "import pgx\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "env = AaduPulliPGXEnv()\n",
    "state = env._init()\n",
    "print('Initial state:', state)\n",
    "actions = env.legal_actions()\n",
    "print('Legal actions:', actions)\n",
    "next_state, reward, done, info = env._step(state, actions[0])\n",
    "print('Next state:', next_state)\n",
    "print('Reward:', reward, 'Done:', done, 'Info:', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae01dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pgx.alphazero'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example: Training AlphaZero on AaduPulliPGXEnv using PGX\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This assumes you have PGX's AlphaZero implementation installed and accessible.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# If PGX's alphazero.py script is available, you can use it like this:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpgx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malphazero\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_alphazero\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Make sure AaduPulliPGXEnv is imported or defined in the same script/notebook\u001b[39;00m\n\u001b[32m      9\u001b[39m env = AaduPulliPGXEnv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pgx.alphazero'"
     ]
    }
   ],
   "source": [
    "# Example: Training AlphaZero on AaduPulliPGXEnv using PGX\n",
    "# This assumes you have PGX's AlphaZero implementation installed and accessible.\n",
    "# If PGX's alphazero.py script is available, you can use it like this:\n",
    "\n",
    "from pgx.alphazero import train_alphazero\n",
    "\n",
    "# Make sure AaduPulliPGXEnv is imported or defined in the same script/notebook\n",
    "\n",
    "env = AaduPulliPGXEnv()\n",
    "\n",
    "# Set AlphaZero hyperparameters (adjust as needed for your game)\n",
    "config = {\n",
    "    'env': env,\n",
    "    'num_simulations': 50,\n",
    "    'num_training_steps': 1000,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-3,\n",
    "    'model': 'mlp',  # or 'resnet' if supported\n",
    "    # Add more config options as needed\n",
    "}\n",
    "\n",
    "# Start training (this may take time and resources)\n",
    "train_alphazero(**config)\n",
    "\n",
    "# For more advanced usage, refer to PGX's AlphaZero documentation and scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
